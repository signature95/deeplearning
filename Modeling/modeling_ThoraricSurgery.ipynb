{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "https://www.kaggle.com/merlecorey/kernel-thoraricsurgery-kdv 에서 데이터 설명을 확인할 수 있다."
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 폐암\n",
    "## 1. 데이터 불러오기"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "source": [
    "import pandas as pd"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "source": [
    "dataset = pd.read_csv('data/ThoraricSurgery.csv')\n",
    "dataset"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>DGN</th>\n",
       "      <th>PRE4</th>\n",
       "      <th>PRE5</th>\n",
       "      <th>PRE6</th>\n",
       "      <th>PRE7</th>\n",
       "      <th>PRE8</th>\n",
       "      <th>PRE9</th>\n",
       "      <th>PRE10</th>\n",
       "      <th>PRE11</th>\n",
       "      <th>PRE14</th>\n",
       "      <th>PRE17</th>\n",
       "      <th>PRE19</th>\n",
       "      <th>PRE25</th>\n",
       "      <th>PRE30</th>\n",
       "      <th>PRE32</th>\n",
       "      <th>AGE</th>\n",
       "      <th>Risk1Yr</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>DGN2</td>\n",
       "      <td>2.88</td>\n",
       "      <td>2.16</td>\n",
       "      <td>PRZ1</td>\n",
       "      <td>F</td>\n",
       "      <td>F</td>\n",
       "      <td>F</td>\n",
       "      <td>T</td>\n",
       "      <td>T</td>\n",
       "      <td>OC14</td>\n",
       "      <td>F</td>\n",
       "      <td>F</td>\n",
       "      <td>F</td>\n",
       "      <td>T</td>\n",
       "      <td>F</td>\n",
       "      <td>60</td>\n",
       "      <td>F</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>DGN3</td>\n",
       "      <td>3.40</td>\n",
       "      <td>1.88</td>\n",
       "      <td>PRZ0</td>\n",
       "      <td>F</td>\n",
       "      <td>F</td>\n",
       "      <td>F</td>\n",
       "      <td>F</td>\n",
       "      <td>F</td>\n",
       "      <td>OC12</td>\n",
       "      <td>F</td>\n",
       "      <td>F</td>\n",
       "      <td>F</td>\n",
       "      <td>T</td>\n",
       "      <td>F</td>\n",
       "      <td>51</td>\n",
       "      <td>F</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>DGN3</td>\n",
       "      <td>2.76</td>\n",
       "      <td>2.08</td>\n",
       "      <td>PRZ1</td>\n",
       "      <td>F</td>\n",
       "      <td>F</td>\n",
       "      <td>F</td>\n",
       "      <td>T</td>\n",
       "      <td>F</td>\n",
       "      <td>OC11</td>\n",
       "      <td>F</td>\n",
       "      <td>F</td>\n",
       "      <td>F</td>\n",
       "      <td>T</td>\n",
       "      <td>F</td>\n",
       "      <td>59</td>\n",
       "      <td>F</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>DGN3</td>\n",
       "      <td>3.68</td>\n",
       "      <td>3.04</td>\n",
       "      <td>PRZ0</td>\n",
       "      <td>F</td>\n",
       "      <td>F</td>\n",
       "      <td>F</td>\n",
       "      <td>F</td>\n",
       "      <td>F</td>\n",
       "      <td>OC11</td>\n",
       "      <td>F</td>\n",
       "      <td>F</td>\n",
       "      <td>F</td>\n",
       "      <td>F</td>\n",
       "      <td>F</td>\n",
       "      <td>54</td>\n",
       "      <td>F</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>DGN3</td>\n",
       "      <td>2.44</td>\n",
       "      <td>0.96</td>\n",
       "      <td>PRZ2</td>\n",
       "      <td>F</td>\n",
       "      <td>T</td>\n",
       "      <td>F</td>\n",
       "      <td>T</td>\n",
       "      <td>T</td>\n",
       "      <td>OC11</td>\n",
       "      <td>F</td>\n",
       "      <td>F</td>\n",
       "      <td>F</td>\n",
       "      <td>T</td>\n",
       "      <td>F</td>\n",
       "      <td>73</td>\n",
       "      <td>T</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>465</th>\n",
       "      <td>466</td>\n",
       "      <td>DGN2</td>\n",
       "      <td>3.88</td>\n",
       "      <td>2.12</td>\n",
       "      <td>PRZ1</td>\n",
       "      <td>F</td>\n",
       "      <td>F</td>\n",
       "      <td>F</td>\n",
       "      <td>T</td>\n",
       "      <td>F</td>\n",
       "      <td>OC13</td>\n",
       "      <td>F</td>\n",
       "      <td>F</td>\n",
       "      <td>F</td>\n",
       "      <td>T</td>\n",
       "      <td>F</td>\n",
       "      <td>63</td>\n",
       "      <td>F</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>466</th>\n",
       "      <td>467</td>\n",
       "      <td>DGN3</td>\n",
       "      <td>3.76</td>\n",
       "      <td>3.12</td>\n",
       "      <td>PRZ0</td>\n",
       "      <td>F</td>\n",
       "      <td>F</td>\n",
       "      <td>F</td>\n",
       "      <td>F</td>\n",
       "      <td>F</td>\n",
       "      <td>OC11</td>\n",
       "      <td>F</td>\n",
       "      <td>F</td>\n",
       "      <td>F</td>\n",
       "      <td>T</td>\n",
       "      <td>F</td>\n",
       "      <td>61</td>\n",
       "      <td>F</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>467</th>\n",
       "      <td>468</td>\n",
       "      <td>DGN3</td>\n",
       "      <td>3.04</td>\n",
       "      <td>2.08</td>\n",
       "      <td>PRZ1</td>\n",
       "      <td>F</td>\n",
       "      <td>F</td>\n",
       "      <td>F</td>\n",
       "      <td>T</td>\n",
       "      <td>F</td>\n",
       "      <td>OC13</td>\n",
       "      <td>F</td>\n",
       "      <td>F</td>\n",
       "      <td>F</td>\n",
       "      <td>F</td>\n",
       "      <td>F</td>\n",
       "      <td>52</td>\n",
       "      <td>F</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>468</th>\n",
       "      <td>469</td>\n",
       "      <td>DGN3</td>\n",
       "      <td>1.96</td>\n",
       "      <td>1.68</td>\n",
       "      <td>PRZ1</td>\n",
       "      <td>F</td>\n",
       "      <td>F</td>\n",
       "      <td>F</td>\n",
       "      <td>T</td>\n",
       "      <td>T</td>\n",
       "      <td>OC12</td>\n",
       "      <td>F</td>\n",
       "      <td>F</td>\n",
       "      <td>F</td>\n",
       "      <td>T</td>\n",
       "      <td>F</td>\n",
       "      <td>79</td>\n",
       "      <td>F</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>469</th>\n",
       "      <td>470</td>\n",
       "      <td>DGN3</td>\n",
       "      <td>4.72</td>\n",
       "      <td>3.56</td>\n",
       "      <td>PRZ0</td>\n",
       "      <td>F</td>\n",
       "      <td>F</td>\n",
       "      <td>F</td>\n",
       "      <td>F</td>\n",
       "      <td>F</td>\n",
       "      <td>OC12</td>\n",
       "      <td>F</td>\n",
       "      <td>F</td>\n",
       "      <td>F</td>\n",
       "      <td>T</td>\n",
       "      <td>F</td>\n",
       "      <td>51</td>\n",
       "      <td>F</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>470 rows × 18 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      id   DGN  PRE4  PRE5  PRE6 PRE7 PRE8 PRE9 PRE10 PRE11 PRE14 PRE17 PRE19  \\\n",
       "0      1  DGN2  2.88  2.16  PRZ1    F    F    F     T     T  OC14     F     F   \n",
       "1      2  DGN3  3.40  1.88  PRZ0    F    F    F     F     F  OC12     F     F   \n",
       "2      3  DGN3  2.76  2.08  PRZ1    F    F    F     T     F  OC11     F     F   \n",
       "3      4  DGN3  3.68  3.04  PRZ0    F    F    F     F     F  OC11     F     F   \n",
       "4      5  DGN3  2.44  0.96  PRZ2    F    T    F     T     T  OC11     F     F   \n",
       "..   ...   ...   ...   ...   ...  ...  ...  ...   ...   ...   ...   ...   ...   \n",
       "465  466  DGN2  3.88  2.12  PRZ1    F    F    F     T     F  OC13     F     F   \n",
       "466  467  DGN3  3.76  3.12  PRZ0    F    F    F     F     F  OC11     F     F   \n",
       "467  468  DGN3  3.04  2.08  PRZ1    F    F    F     T     F  OC13     F     F   \n",
       "468  469  DGN3  1.96  1.68  PRZ1    F    F    F     T     T  OC12     F     F   \n",
       "469  470  DGN3  4.72  3.56  PRZ0    F    F    F     F     F  OC12     F     F   \n",
       "\n",
       "    PRE25 PRE30 PRE32  AGE Risk1Yr  \n",
       "0       F     T     F   60       F  \n",
       "1       F     T     F   51       F  \n",
       "2       F     T     F   59       F  \n",
       "3       F     F     F   54       F  \n",
       "4       F     T     F   73       T  \n",
       "..    ...   ...   ...  ...     ...  \n",
       "465     F     T     F   63       F  \n",
       "466     F     T     F   61       F  \n",
       "467     F     F     F   52       F  \n",
       "468     F     T     F   79       F  \n",
       "469     F     T     F   51       F  \n",
       "\n",
       "[470 rows x 18 columns]"
      ]
     },
     "metadata": {},
     "execution_count": 11
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "source": [
    "# id column 삭제\n",
    "dataset = dataset.drop(dataset.columns[0], axis=1)\n",
    "\n",
    "# columns 명칭 수정\n",
    "col = ['Diagnosis','Forced_Capacity','Forced_Expiration','Zubrod_scale','Pain',' Haemoptysis','Dyspnoea',\n",
    "       'Cough','Weakness','Size_of_tumor','diabetes','MI_6months','PAD','Smoker','Asthmatic','Age','Risk_1y']\n",
    "\n",
    "dataset.columns = col\n",
    "dataset"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Diagnosis</th>\n",
       "      <th>Forced_Capacity</th>\n",
       "      <th>Forced_Expiration</th>\n",
       "      <th>Zubrod_scale</th>\n",
       "      <th>Pain</th>\n",
       "      <th>Haemoptysis</th>\n",
       "      <th>Dyspnoea</th>\n",
       "      <th>Cough</th>\n",
       "      <th>Weakness</th>\n",
       "      <th>Size_of_tumor</th>\n",
       "      <th>diabetes</th>\n",
       "      <th>MI_6months</th>\n",
       "      <th>PAD</th>\n",
       "      <th>Smoker</th>\n",
       "      <th>Asthmatic</th>\n",
       "      <th>Age</th>\n",
       "      <th>Risk_1y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>DGN2</td>\n",
       "      <td>2.88</td>\n",
       "      <td>2.16</td>\n",
       "      <td>PRZ1</td>\n",
       "      <td>F</td>\n",
       "      <td>F</td>\n",
       "      <td>F</td>\n",
       "      <td>T</td>\n",
       "      <td>T</td>\n",
       "      <td>OC14</td>\n",
       "      <td>F</td>\n",
       "      <td>F</td>\n",
       "      <td>F</td>\n",
       "      <td>T</td>\n",
       "      <td>F</td>\n",
       "      <td>60</td>\n",
       "      <td>F</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>DGN3</td>\n",
       "      <td>3.40</td>\n",
       "      <td>1.88</td>\n",
       "      <td>PRZ0</td>\n",
       "      <td>F</td>\n",
       "      <td>F</td>\n",
       "      <td>F</td>\n",
       "      <td>F</td>\n",
       "      <td>F</td>\n",
       "      <td>OC12</td>\n",
       "      <td>F</td>\n",
       "      <td>F</td>\n",
       "      <td>F</td>\n",
       "      <td>T</td>\n",
       "      <td>F</td>\n",
       "      <td>51</td>\n",
       "      <td>F</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>DGN3</td>\n",
       "      <td>2.76</td>\n",
       "      <td>2.08</td>\n",
       "      <td>PRZ1</td>\n",
       "      <td>F</td>\n",
       "      <td>F</td>\n",
       "      <td>F</td>\n",
       "      <td>T</td>\n",
       "      <td>F</td>\n",
       "      <td>OC11</td>\n",
       "      <td>F</td>\n",
       "      <td>F</td>\n",
       "      <td>F</td>\n",
       "      <td>T</td>\n",
       "      <td>F</td>\n",
       "      <td>59</td>\n",
       "      <td>F</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>DGN3</td>\n",
       "      <td>3.68</td>\n",
       "      <td>3.04</td>\n",
       "      <td>PRZ0</td>\n",
       "      <td>F</td>\n",
       "      <td>F</td>\n",
       "      <td>F</td>\n",
       "      <td>F</td>\n",
       "      <td>F</td>\n",
       "      <td>OC11</td>\n",
       "      <td>F</td>\n",
       "      <td>F</td>\n",
       "      <td>F</td>\n",
       "      <td>F</td>\n",
       "      <td>F</td>\n",
       "      <td>54</td>\n",
       "      <td>F</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>DGN3</td>\n",
       "      <td>2.44</td>\n",
       "      <td>0.96</td>\n",
       "      <td>PRZ2</td>\n",
       "      <td>F</td>\n",
       "      <td>T</td>\n",
       "      <td>F</td>\n",
       "      <td>T</td>\n",
       "      <td>T</td>\n",
       "      <td>OC11</td>\n",
       "      <td>F</td>\n",
       "      <td>F</td>\n",
       "      <td>F</td>\n",
       "      <td>T</td>\n",
       "      <td>F</td>\n",
       "      <td>73</td>\n",
       "      <td>T</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>465</th>\n",
       "      <td>DGN2</td>\n",
       "      <td>3.88</td>\n",
       "      <td>2.12</td>\n",
       "      <td>PRZ1</td>\n",
       "      <td>F</td>\n",
       "      <td>F</td>\n",
       "      <td>F</td>\n",
       "      <td>T</td>\n",
       "      <td>F</td>\n",
       "      <td>OC13</td>\n",
       "      <td>F</td>\n",
       "      <td>F</td>\n",
       "      <td>F</td>\n",
       "      <td>T</td>\n",
       "      <td>F</td>\n",
       "      <td>63</td>\n",
       "      <td>F</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>466</th>\n",
       "      <td>DGN3</td>\n",
       "      <td>3.76</td>\n",
       "      <td>3.12</td>\n",
       "      <td>PRZ0</td>\n",
       "      <td>F</td>\n",
       "      <td>F</td>\n",
       "      <td>F</td>\n",
       "      <td>F</td>\n",
       "      <td>F</td>\n",
       "      <td>OC11</td>\n",
       "      <td>F</td>\n",
       "      <td>F</td>\n",
       "      <td>F</td>\n",
       "      <td>T</td>\n",
       "      <td>F</td>\n",
       "      <td>61</td>\n",
       "      <td>F</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>467</th>\n",
       "      <td>DGN3</td>\n",
       "      <td>3.04</td>\n",
       "      <td>2.08</td>\n",
       "      <td>PRZ1</td>\n",
       "      <td>F</td>\n",
       "      <td>F</td>\n",
       "      <td>F</td>\n",
       "      <td>T</td>\n",
       "      <td>F</td>\n",
       "      <td>OC13</td>\n",
       "      <td>F</td>\n",
       "      <td>F</td>\n",
       "      <td>F</td>\n",
       "      <td>F</td>\n",
       "      <td>F</td>\n",
       "      <td>52</td>\n",
       "      <td>F</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>468</th>\n",
       "      <td>DGN3</td>\n",
       "      <td>1.96</td>\n",
       "      <td>1.68</td>\n",
       "      <td>PRZ1</td>\n",
       "      <td>F</td>\n",
       "      <td>F</td>\n",
       "      <td>F</td>\n",
       "      <td>T</td>\n",
       "      <td>T</td>\n",
       "      <td>OC12</td>\n",
       "      <td>F</td>\n",
       "      <td>F</td>\n",
       "      <td>F</td>\n",
       "      <td>T</td>\n",
       "      <td>F</td>\n",
       "      <td>79</td>\n",
       "      <td>F</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>469</th>\n",
       "      <td>DGN3</td>\n",
       "      <td>4.72</td>\n",
       "      <td>3.56</td>\n",
       "      <td>PRZ0</td>\n",
       "      <td>F</td>\n",
       "      <td>F</td>\n",
       "      <td>F</td>\n",
       "      <td>F</td>\n",
       "      <td>F</td>\n",
       "      <td>OC12</td>\n",
       "      <td>F</td>\n",
       "      <td>F</td>\n",
       "      <td>F</td>\n",
       "      <td>T</td>\n",
       "      <td>F</td>\n",
       "      <td>51</td>\n",
       "      <td>F</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>470 rows × 17 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    Diagnosis  Forced_Capacity  Forced_Expiration Zubrod_scale Pain  \\\n",
       "0        DGN2             2.88               2.16         PRZ1    F   \n",
       "1        DGN3             3.40               1.88         PRZ0    F   \n",
       "2        DGN3             2.76               2.08         PRZ1    F   \n",
       "3        DGN3             3.68               3.04         PRZ0    F   \n",
       "4        DGN3             2.44               0.96         PRZ2    F   \n",
       "..        ...              ...                ...          ...  ...   \n",
       "465      DGN2             3.88               2.12         PRZ1    F   \n",
       "466      DGN3             3.76               3.12         PRZ0    F   \n",
       "467      DGN3             3.04               2.08         PRZ1    F   \n",
       "468      DGN3             1.96               1.68         PRZ1    F   \n",
       "469      DGN3             4.72               3.56         PRZ0    F   \n",
       "\n",
       "     Haemoptysis Dyspnoea Cough Weakness Size_of_tumor diabetes MI_6months  \\\n",
       "0              F        F     T        T          OC14        F          F   \n",
       "1              F        F     F        F          OC12        F          F   \n",
       "2              F        F     T        F          OC11        F          F   \n",
       "3              F        F     F        F          OC11        F          F   \n",
       "4              T        F     T        T          OC11        F          F   \n",
       "..           ...      ...   ...      ...           ...      ...        ...   \n",
       "465            F        F     T        F          OC13        F          F   \n",
       "466            F        F     F        F          OC11        F          F   \n",
       "467            F        F     T        F          OC13        F          F   \n",
       "468            F        F     T        T          OC12        F          F   \n",
       "469            F        F     F        F          OC12        F          F   \n",
       "\n",
       "    PAD Smoker Asthmatic  Age Risk_1y  \n",
       "0     F      T         F   60       F  \n",
       "1     F      T         F   51       F  \n",
       "2     F      T         F   59       F  \n",
       "3     F      F         F   54       F  \n",
       "4     F      T         F   73       T  \n",
       "..   ..    ...       ...  ...     ...  \n",
       "465   F      T         F   63       F  \n",
       "466   F      T         F   61       F  \n",
       "467   F      F         F   52       F  \n",
       "468   F      T         F   79       F  \n",
       "469   F      T         F   51       F  \n",
       "\n",
       "[470 rows x 17 columns]"
      ]
     },
     "metadata": {},
     "execution_count": 12
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "source": [
    "# text로 불러오기\n",
    "\n",
    "data = np.loadtxt('data/ThoraricSurgery (1).csv', delimiter=',')\n",
    "data"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "array([[293.  ,   1.  ,   3.8 , ...,   0.  ,  62.  ,   0.  ],\n",
       "       [  1.  ,   2.  ,   2.88, ...,   0.  ,  60.  ,   0.  ],\n",
       "       [  8.  ,   2.  ,   3.19, ...,   0.  ,  66.  ,   1.  ],\n",
       "       ...,\n",
       "       [406.  ,   6.  ,   5.36, ...,   0.  ,  62.  ,   0.  ],\n",
       "       [ 25.  ,   8.  ,   4.32, ...,   0.  ,  58.  ,   1.  ],\n",
       "       [447.  ,   8.  ,   5.2 , ...,   0.  ,  49.  ,   0.  ]])"
      ]
     },
     "metadata": {},
     "execution_count": 26
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "source": [
    "data.shape"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(470, 18)"
      ]
     },
     "metadata": {},
     "execution_count": 28
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 2. 모델링 구축"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "source": [
    "# feature, target 분리\n",
    "\n",
    "X = data[:,0:17]\n",
    "y = data[:,17]"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "source": [
    "np.random.randint(10)"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "metadata": {},
     "execution_count": 30
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(30,                         # 30개의 노드\n",
    "                activation='relu',          # 활성화 함수로 relu함수로 실행\n",
    "                input_dim = 17))            # 17개의 feature를 input_dim으로 설정\n",
    "                                            # 17개의 feature가 30개의 노드로 연결되어 은닉층에 투과된다.\n",
    "model.add(Dense(1,                          # 1개의 결과를 도출할 것임.\n",
    "                activation = 'sigmoid'))    # 출력은 0, 1으로 뽑는 활성화 함수 sigmoid 실행"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "source": [
    "model.compile(loss = 'binary_crossentropy', # loss 측정 함수로 채택\n",
    "              optimizer='adam',             # 최적화를 adam으로 지정\n",
    "              metrics=['accuracy', 'mse'])  # 정확도와 MSE를 출력하라는 의미\n",
    "model.fit(X, y,                             # feature, label 지정\n",
    "          epochs = 100,                     # 훈련은 100회 진행\n",
    "          batch_size= 10)                   # 한번에 10개 넣기"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch 1/100\n",
      "47/47 [==============================] - 1s 5ms/step - loss: 5.6457 - accuracy: 0.8255 - mse: 0.1676\n",
      "Epoch 2/100\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 1.1915 - accuracy: 0.7277 - mse: 0.2115\n",
      "Epoch 3/100\n",
      "47/47 [==============================] - 0s 1ms/step - loss: 0.5448 - accuracy: 0.8298 - mse: 0.1441\n",
      "Epoch 4/100\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 0.5089 - accuracy: 0.8447 - mse: 0.1416\n",
      "Epoch 5/100\n",
      "47/47 [==============================] - 0s 3ms/step - loss: 0.5222 - accuracy: 0.8468 - mse: 0.1410\n",
      "Epoch 6/100\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 0.5025 - accuracy: 0.8149 - mse: 0.1501\n",
      "Epoch 7/100\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 0.4733 - accuracy: 0.8511 - mse: 0.1356\n",
      "Epoch 8/100\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 0.4624 - accuracy: 0.8532 - mse: 0.1336\n",
      "Epoch 9/100\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 0.4604 - accuracy: 0.8489 - mse: 0.1359\n",
      "Epoch 10/100\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 0.5121 - accuracy: 0.8255 - mse: 0.1433\n",
      "Epoch 11/100\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 0.4646 - accuracy: 0.8468 - mse: 0.1350\n",
      "Epoch 12/100\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 0.4419 - accuracy: 0.8511 - mse: 0.1330\n",
      "Epoch 13/100\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 0.4542 - accuracy: 0.8489 - mse: 0.1338\n",
      "Epoch 14/100\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 0.4600 - accuracy: 0.8362 - mse: 0.1361\n",
      "Epoch 15/100\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 0.4328 - accuracy: 0.8511 - mse: 0.1302\n",
      "Epoch 16/100\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 0.4292 - accuracy: 0.8489 - mse: 0.1282\n",
      "Epoch 17/100\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 0.4158 - accuracy: 0.8511 - mse: 0.1247\n",
      "Epoch 18/100\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 0.4368 - accuracy: 0.8489 - mse: 0.1299\n",
      "Epoch 19/100\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 0.4236 - accuracy: 0.8489 - mse: 0.1277\n",
      "Epoch 20/100\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 0.4285 - accuracy: 0.8489 - mse: 0.1264\n",
      "Epoch 21/100\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 0.4382 - accuracy: 0.8489 - mse: 0.1284\n",
      "Epoch 22/100\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 0.4110 - accuracy: 0.8447 - mse: 0.1251\n",
      "Epoch 23/100\n",
      "47/47 [==============================] - 0s 1ms/step - loss: 0.4129 - accuracy: 0.8468 - mse: 0.1257\n",
      "Epoch 24/100\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 0.4073 - accuracy: 0.8447 - mse: 0.1256\n",
      "Epoch 25/100\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 0.4603 - accuracy: 0.8340 - mse: 0.1356\n",
      "Epoch 26/100\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 0.4195 - accuracy: 0.8489 - mse: 0.1267\n",
      "Epoch 27/100\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 0.4447 - accuracy: 0.8340 - mse: 0.1350\n",
      "Epoch 28/100\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 0.4644 - accuracy: 0.8426 - mse: 0.1330\n",
      "Epoch 29/100\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 0.4161 - accuracy: 0.8511 - mse: 0.1261\n",
      "Epoch 30/100\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 0.4224 - accuracy: 0.8532 - mse: 0.1264\n",
      "Epoch 31/100\n",
      "47/47 [==============================] - 0s 3ms/step - loss: 0.4302 - accuracy: 0.8553 - mse: 0.1251\n",
      "Epoch 32/100\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 0.4122 - accuracy: 0.8468 - mse: 0.1262\n",
      "Epoch 33/100\n",
      "47/47 [==============================] - 0s 3ms/step - loss: 0.4016 - accuracy: 0.8468 - mse: 0.1225\n",
      "Epoch 34/100\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 0.4340 - accuracy: 0.8511 - mse: 0.1249\n",
      "Epoch 35/100\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 0.4449 - accuracy: 0.8277 - mse: 0.1314\n",
      "Epoch 36/100\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 0.4334 - accuracy: 0.8511 - mse: 0.1289\n",
      "Epoch 37/100\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 0.4303 - accuracy: 0.8383 - mse: 0.1246\n",
      "Epoch 38/100\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 0.4483 - accuracy: 0.8511 - mse: 0.1317\n",
      "Epoch 39/100\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 0.4122 - accuracy: 0.8532 - mse: 0.1227\n",
      "Epoch 40/100\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 0.4110 - accuracy: 0.8511 - mse: 0.1232\n",
      "Epoch 41/100\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 0.4294 - accuracy: 0.8426 - mse: 0.1258\n",
      "Epoch 42/100\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 0.4495 - accuracy: 0.8277 - mse: 0.1355\n",
      "Epoch 43/100\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 0.4622 - accuracy: 0.8319 - mse: 0.1306\n",
      "Epoch 44/100\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 0.4100 - accuracy: 0.8489 - mse: 0.1239\n",
      "Epoch 45/100\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 0.4164 - accuracy: 0.8511 - mse: 0.1247\n",
      "Epoch 46/100\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 0.4201 - accuracy: 0.8489 - mse: 0.1249\n",
      "Epoch 47/100\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 0.4523 - accuracy: 0.8255 - mse: 0.1333\n",
      "Epoch 48/100\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 0.4210 - accuracy: 0.8511 - mse: 0.1219\n",
      "Epoch 49/100\n",
      "47/47 [==============================] - 0s 3ms/step - loss: 0.4159 - accuracy: 0.8447 - mse: 0.1251\n",
      "Epoch 50/100\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 0.3968 - accuracy: 0.8489 - mse: 0.1202\n",
      "Epoch 51/100\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 0.3897 - accuracy: 0.8511 - mse: 0.1168\n",
      "Epoch 52/100\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 0.4073 - accuracy: 0.8468 - mse: 0.1252\n",
      "Epoch 53/100\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 0.3915 - accuracy: 0.8468 - mse: 0.1194\n",
      "Epoch 54/100\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 0.4071 - accuracy: 0.8489 - mse: 0.1227\n",
      "Epoch 55/100\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.4134 - accuracy: 0.8383 - mse: 0.1256\n",
      "Epoch 56/100\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 0.3904 - accuracy: 0.8532 - mse: 0.1168\n",
      "Epoch 57/100\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 0.4207 - accuracy: 0.8447 - mse: 0.1265\n",
      "Epoch 58/100\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 0.4381 - accuracy: 0.8447 - mse: 0.1302\n",
      "Epoch 59/100\n",
      "47/47 [==============================] - 0s 3ms/step - loss: 0.4185 - accuracy: 0.8489 - mse: 0.1215\n",
      "Epoch 60/100\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 0.4166 - accuracy: 0.8383 - mse: 0.1270\n",
      "Epoch 61/100\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.4030 - accuracy: 0.8468 - mse: 0.1213\n",
      "Epoch 62/100\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 0.4162 - accuracy: 0.8489 - mse: 0.1237\n",
      "Epoch 63/100\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 0.4134 - accuracy: 0.8511 - mse: 0.1216\n",
      "Epoch 64/100\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 0.3972 - accuracy: 0.8489 - mse: 0.1218\n",
      "Epoch 65/100\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 0.3967 - accuracy: 0.8468 - mse: 0.1184\n",
      "Epoch 66/100\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 0.4165 - accuracy: 0.8511 - mse: 0.1243\n",
      "Epoch 67/100\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 0.4035 - accuracy: 0.8468 - mse: 0.1203\n",
      "Epoch 68/100\n",
      "47/47 [==============================] - 0s 3ms/step - loss: 0.3997 - accuracy: 0.8574 - mse: 0.1191\n",
      "Epoch 69/100\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 0.4348 - accuracy: 0.8383 - mse: 0.1284\n",
      "Epoch 70/100\n",
      "47/47 [==============================] - 0s 3ms/step - loss: 0.4211 - accuracy: 0.8447 - mse: 0.1287\n",
      "Epoch 71/100\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 0.4367 - accuracy: 0.8213 - mse: 0.1302\n",
      "Epoch 72/100\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 0.4073 - accuracy: 0.8489 - mse: 0.1191\n",
      "Epoch 73/100\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 0.4389 - accuracy: 0.8553 - mse: 0.1216\n",
      "Epoch 74/100\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 0.3977 - accuracy: 0.8447 - mse: 0.1215\n",
      "Epoch 75/100\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 0.4018 - accuracy: 0.8447 - mse: 0.1224\n",
      "Epoch 76/100\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 0.4183 - accuracy: 0.8362 - mse: 0.1269\n",
      "Epoch 77/100\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 0.3927 - accuracy: 0.8404 - mse: 0.1193\n",
      "Epoch 78/100\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 0.4303 - accuracy: 0.8319 - mse: 0.1267\n",
      "Epoch 79/100\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 0.4318 - accuracy: 0.8383 - mse: 0.1284\n",
      "Epoch 80/100\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 0.4027 - accuracy: 0.8468 - mse: 0.1222\n",
      "Epoch 81/100\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 0.4109 - accuracy: 0.8511 - mse: 0.1237\n",
      "Epoch 82/100\n",
      "47/47 [==============================] - 0s 1ms/step - loss: 0.3932 - accuracy: 0.8511 - mse: 0.1184\n",
      "Epoch 83/100\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 0.3970 - accuracy: 0.8511 - mse: 0.1182\n",
      "Epoch 84/100\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 0.4064 - accuracy: 0.8574 - mse: 0.1180\n",
      "Epoch 85/100\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 0.4043 - accuracy: 0.8511 - mse: 0.1217\n",
      "Epoch 86/100\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 0.3998 - accuracy: 0.8638 - mse: 0.1175\n",
      "Epoch 87/100\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 0.3911 - accuracy: 0.8511 - mse: 0.1174\n",
      "Epoch 88/100\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 0.3964 - accuracy: 0.8511 - mse: 0.1195\n",
      "Epoch 89/100\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 0.4115 - accuracy: 0.8447 - mse: 0.1243\n",
      "Epoch 90/100\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 0.4102 - accuracy: 0.8553 - mse: 0.1226\n",
      "Epoch 91/100\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 0.3929 - accuracy: 0.8532 - mse: 0.1174\n",
      "Epoch 92/100\n",
      "47/47 [==============================] - 0s 1ms/step - loss: 0.3964 - accuracy: 0.8447 - mse: 0.1191\n",
      "Epoch 93/100\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 0.4091 - accuracy: 0.8426 - mse: 0.1201\n",
      "Epoch 94/100\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 0.3819 - accuracy: 0.8574 - mse: 0.1142\n",
      "Epoch 95/100\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 0.4142 - accuracy: 0.8489 - mse: 0.1233\n",
      "Epoch 96/100\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 0.4014 - accuracy: 0.8511 - mse: 0.1207\n",
      "Epoch 97/100\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 0.4118 - accuracy: 0.8532 - mse: 0.1199\n",
      "Epoch 98/100\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 0.4005 - accuracy: 0.8404 - mse: 0.1220\n",
      "Epoch 99/100\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.3985 - accuracy: 0.8511 - mse: 0.1199\n",
      "Epoch 100/100\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 0.3821 - accuracy: 0.8511 - mse: 0.1151\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fc1103e5040>"
      ]
     },
     "metadata": {},
     "execution_count": 35
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(30,                         # 30개의 노드\n",
    "                activation='softmax',       # 활성화 함수로 relu함수로 실행\n",
    "                input_dim = 17))            # 17개의 feature를 input_dim으로 설정\n",
    "                                            # 17개의 feature가 30개의 노드로 연결되어 은닉층에 투과된다.\n",
    "model.add(Dense(1,                          # 1개의 결과를 도출할 것임.\n",
    "                activation = 'sigmoid'))    # 출력은 0, 1으로 뽑는 활성화 함수 sigmoid 실행"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "source": [
    "model.compile(loss = 'binary_crossentropy', # loss 측정 함수로 채택\n",
    "              optimizer='adam',             # 최적화를 adam으로 지정\n",
    "              metrics=['accuracy', 'mse'])  # 정확도와 MSE를 출력하라는 의미\n",
    "model.fit(X, y,                             # feature, label 지정\n",
    "          epochs = 100,                     # 훈련은 100회 진행\n",
    "          batch_size= 10)                   # 한번에 10개 넣기"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch 1/100\n",
      "47/47 [==============================] - 1s 2ms/step - loss: 0.6110 - accuracy: 0.8404 - mse: 0.2093\n",
      "Epoch 2/100\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 0.5566 - accuracy: 0.8426 - mse: 0.1829\n",
      "Epoch 3/100\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 0.5352 - accuracy: 0.8468 - mse: 0.1729\n",
      "Epoch 4/100\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 0.5188 - accuracy: 0.8511 - mse: 0.1654\n",
      "Epoch 5/100\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 0.5043 - accuracy: 0.8511 - mse: 0.1589\n",
      "Epoch 6/100\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 0.4917 - accuracy: 0.8511 - mse: 0.1534\n",
      "Epoch 7/100\n",
      "47/47 [==============================] - 0s 3ms/step - loss: 0.4805 - accuracy: 0.8511 - mse: 0.1486\n",
      "Epoch 8/100\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 0.4706 - accuracy: 0.8511 - mse: 0.1445\n",
      "Epoch 9/100\n",
      "47/47 [==============================] - 0s 3ms/step - loss: 0.4629 - accuracy: 0.8511 - mse: 0.1415\n",
      "Epoch 10/100\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 0.4562 - accuracy: 0.8511 - mse: 0.1388\n",
      "Epoch 11/100\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 0.4508 - accuracy: 0.8511 - mse: 0.1368\n",
      "Epoch 12/100\n",
      "47/47 [==============================] - 0s 3ms/step - loss: 0.4460 - accuracy: 0.8511 - mse: 0.1350\n",
      "Epoch 13/100\n",
      "47/47 [==============================] - 0s 3ms/step - loss: 0.4424 - accuracy: 0.8511 - mse: 0.1337\n",
      "Epoch 14/100\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 0.4386 - accuracy: 0.8511 - mse: 0.1324\n",
      "Epoch 15/100\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 0.4356 - accuracy: 0.8511 - mse: 0.1313\n",
      "Epoch 16/100\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 0.4332 - accuracy: 0.8511 - mse: 0.1305\n",
      "Epoch 17/100\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 0.4311 - accuracy: 0.8511 - mse: 0.1298\n",
      "Epoch 18/100\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 0.4292 - accuracy: 0.8511 - mse: 0.1292\n",
      "Epoch 19/100\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 0.4277 - accuracy: 0.8511 - mse: 0.1287\n",
      "Epoch 20/100\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.4262 - accuracy: 0.8511 - mse: 0.1283\n",
      "Epoch 21/100\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 0.4251 - accuracy: 0.8511 - mse: 0.1279\n",
      "Epoch 22/100\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 0.4240 - accuracy: 0.8511 - mse: 0.1276\n",
      "Epoch 23/100\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 0.4231 - accuracy: 0.8511 - mse: 0.1273\n",
      "Epoch 24/100\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 0.4227 - accuracy: 0.8511 - mse: 0.1272\n",
      "Epoch 25/100\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 0.4219 - accuracy: 0.8511 - mse: 0.1269\n",
      "Epoch 26/100\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 0.4215 - accuracy: 0.8511 - mse: 0.1269\n",
      "Epoch 27/100\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.4209 - accuracy: 0.8511 - mse: 0.1266\n",
      "Epoch 28/100\n",
      "47/47 [==============================] - 0s 3ms/step - loss: 0.4206 - accuracy: 0.8511 - mse: 0.1266\n",
      "Epoch 29/100\n",
      "47/47 [==============================] - 0s 3ms/step - loss: 0.4202 - accuracy: 0.8511 - mse: 0.1264\n",
      "Epoch 30/100\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 0.4199 - accuracy: 0.8511 - mse: 0.1263\n",
      "Epoch 31/100\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 0.4197 - accuracy: 0.8511 - mse: 0.1263\n",
      "Epoch 32/100\n",
      "47/47 [==============================] - 0s 1ms/step - loss: 0.4195 - accuracy: 0.8511 - mse: 0.1262\n",
      "Epoch 33/100\n",
      "47/47 [==============================] - 0s 1ms/step - loss: 0.4194 - accuracy: 0.8511 - mse: 0.1262\n",
      "Epoch 34/100\n",
      "47/47 [==============================] - 0s 1ms/step - loss: 0.4190 - accuracy: 0.8511 - mse: 0.1261\n",
      "Epoch 35/100\n",
      "47/47 [==============================] - 0s 1ms/step - loss: 0.4189 - accuracy: 0.8511 - mse: 0.1261\n",
      "Epoch 36/100\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.4188 - accuracy: 0.8511 - mse: 0.1260\n",
      "Epoch 37/100\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 0.4187 - accuracy: 0.8511 - mse: 0.1260\n",
      "Epoch 38/100\n",
      "47/47 [==============================] - 0s 3ms/step - loss: 0.4185 - accuracy: 0.8511 - mse: 0.1259\n",
      "Epoch 39/100\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.4185 - accuracy: 0.8511 - mse: 0.1259\n",
      "Epoch 40/100\n",
      "47/47 [==============================] - 0s 1ms/step - loss: 0.4184 - accuracy: 0.8511 - mse: 0.1259\n",
      "Epoch 41/100\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 0.4184 - accuracy: 0.8511 - mse: 0.1259\n",
      "Epoch 42/100\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 0.4181 - accuracy: 0.8511 - mse: 0.1258\n",
      "Epoch 43/100\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 0.4180 - accuracy: 0.8511 - mse: 0.1257\n",
      "Epoch 44/100\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 0.4180 - accuracy: 0.8511 - mse: 0.1257\n",
      "Epoch 45/100\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 0.4178 - accuracy: 0.8511 - mse: 0.1257\n",
      "Epoch 46/100\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 0.4180 - accuracy: 0.8511 - mse: 0.1257\n",
      "Epoch 47/100\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 0.4177 - accuracy: 0.8511 - mse: 0.1257\n",
      "Epoch 48/100\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 0.4181 - accuracy: 0.8511 - mse: 0.1258\n",
      "Epoch 49/100\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 0.4179 - accuracy: 0.8511 - mse: 0.1257\n",
      "Epoch 50/100\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 0.4178 - accuracy: 0.8511 - mse: 0.1256\n",
      "Epoch 51/100\n",
      "47/47 [==============================] - 0s 1ms/step - loss: 0.4177 - accuracy: 0.8511 - mse: 0.1257\n",
      "Epoch 52/100\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 0.4175 - accuracy: 0.8511 - mse: 0.1255\n",
      "Epoch 53/100\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 0.4174 - accuracy: 0.8511 - mse: 0.1255\n",
      "Epoch 54/100\n",
      "47/47 [==============================] - 0s 1ms/step - loss: 0.4175 - accuracy: 0.8511 - mse: 0.1256\n",
      "Epoch 55/100\n",
      "47/47 [==============================] - 0s 1ms/step - loss: 0.4171 - accuracy: 0.8511 - mse: 0.1254\n",
      "Epoch 56/100\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 0.4179 - accuracy: 0.8511 - mse: 0.1257\n",
      "Epoch 57/100\n",
      "47/47 [==============================] - 0s 1ms/step - loss: 0.4174 - accuracy: 0.8511 - mse: 0.1255\n",
      "Epoch 58/100\n",
      "47/47 [==============================] - 0s 1ms/step - loss: 0.4172 - accuracy: 0.8511 - mse: 0.1254\n",
      "Epoch 59/100\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 0.4174 - accuracy: 0.8511 - mse: 0.1255\n",
      "Epoch 60/100\n",
      "47/47 [==============================] - 0s 3ms/step - loss: 0.4169 - accuracy: 0.8511 - mse: 0.1253\n",
      "Epoch 61/100\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 0.4169 - accuracy: 0.8511 - mse: 0.1253\n",
      "Epoch 62/100\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 0.4171 - accuracy: 0.8511 - mse: 0.1254\n",
      "Epoch 63/100\n",
      "47/47 [==============================] - 0s 1ms/step - loss: 0.4171 - accuracy: 0.8511 - mse: 0.1254\n",
      "Epoch 64/100\n",
      "47/47 [==============================] - 0s 3ms/step - loss: 0.4170 - accuracy: 0.8511 - mse: 0.1253\n",
      "Epoch 65/100\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 0.4172 - accuracy: 0.8511 - mse: 0.1255\n",
      "Epoch 66/100\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 0.4169 - accuracy: 0.8511 - mse: 0.1253\n",
      "Epoch 67/100\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 0.4165 - accuracy: 0.8511 - mse: 0.1251\n",
      "Epoch 68/100\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 0.4169 - accuracy: 0.8511 - mse: 0.1253\n",
      "Epoch 69/100\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 0.4164 - accuracy: 0.8511 - mse: 0.1251\n",
      "Epoch 70/100\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 0.4165 - accuracy: 0.8511 - mse: 0.1251\n",
      "Epoch 71/100\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 0.4166 - accuracy: 0.8511 - mse: 0.1252\n",
      "Epoch 72/100\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 0.4166 - accuracy: 0.8511 - mse: 0.1252\n",
      "Epoch 73/100\n",
      "47/47 [==============================] - 0s 1ms/step - loss: 0.4165 - accuracy: 0.8511 - mse: 0.1251\n",
      "Epoch 74/100\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 0.4167 - accuracy: 0.8511 - mse: 0.1253\n",
      "Epoch 75/100\n",
      "47/47 [==============================] - 0s 1ms/step - loss: 0.4165 - accuracy: 0.8511 - mse: 0.1251\n",
      "Epoch 76/100\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 0.4164 - accuracy: 0.8511 - mse: 0.1251\n",
      "Epoch 77/100\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 0.4161 - accuracy: 0.8511 - mse: 0.1250\n",
      "Epoch 78/100\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 0.4164 - accuracy: 0.8511 - mse: 0.1251\n",
      "Epoch 79/100\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 0.4159 - accuracy: 0.8511 - mse: 0.1249\n",
      "Epoch 80/100\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 0.4162 - accuracy: 0.8511 - mse: 0.1250\n",
      "Epoch 81/100\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 0.4161 - accuracy: 0.8511 - mse: 0.1250\n",
      "Epoch 82/100\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 0.4157 - accuracy: 0.8511 - mse: 0.1248\n",
      "Epoch 83/100\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 0.4160 - accuracy: 0.8511 - mse: 0.1250\n",
      "Epoch 84/100\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 0.4166 - accuracy: 0.8511 - mse: 0.1251\n",
      "Epoch 85/100\n",
      "47/47 [==============================] - 0s 1ms/step - loss: 0.4155 - accuracy: 0.8511 - mse: 0.1248\n",
      "Epoch 86/100\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 0.4158 - accuracy: 0.8511 - mse: 0.1249\n",
      "Epoch 87/100\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 0.4155 - accuracy: 0.8511 - mse: 0.1247\n",
      "Epoch 88/100\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 0.4155 - accuracy: 0.8511 - mse: 0.1247\n",
      "Epoch 89/100\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 0.4154 - accuracy: 0.8511 - mse: 0.1247\n",
      "Epoch 90/100\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 0.4158 - accuracy: 0.8511 - mse: 0.1249\n",
      "Epoch 91/100\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 0.4154 - accuracy: 0.8511 - mse: 0.1247\n",
      "Epoch 92/100\n",
      "47/47 [==============================] - 0s 1ms/step - loss: 0.4151 - accuracy: 0.8511 - mse: 0.1246\n",
      "Epoch 93/100\n",
      "47/47 [==============================] - 0s 1ms/step - loss: 0.4153 - accuracy: 0.8511 - mse: 0.1246\n",
      "Epoch 94/100\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 0.4155 - accuracy: 0.8511 - mse: 0.1247\n",
      "Epoch 95/100\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 0.4151 - accuracy: 0.8511 - mse: 0.1246\n",
      "Epoch 96/100\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 0.4150 - accuracy: 0.8511 - mse: 0.1245\n",
      "Epoch 97/100\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 0.4153 - accuracy: 0.8511 - mse: 0.1246\n",
      "Epoch 98/100\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 0.4149 - accuracy: 0.8511 - mse: 0.1245\n",
      "Epoch 99/100\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 0.4151 - accuracy: 0.8511 - mse: 0.1246\n",
      "Epoch 100/100\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 0.4147 - accuracy: 0.8511 - mse: 0.1244\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fc1111030a0>"
      ]
     },
     "metadata": {},
     "execution_count": 37
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "softmax 보다 relu가 더 낳은 결과를 도출한 것을 알 수 있음."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "source": [
    "# 만약 데이터가 적다면?\n",
    "\n",
    "X_new = data[:300,0:17].astype('float64')\n",
    "y_new = data[:300,17]"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(30,                         # 30개의 노드\n",
    "                activation='relu',          # 활성화 함수로 relu함수로 실행\n",
    "                input_dim = 17))            # 17개의 feature를 input_dim으로 설정\n",
    "                                            # 17개의 feature가 30개의 노드로 연결되어 은닉층에 투과된다.\n",
    "model.add(Dense(1,                          # 1개의 결과를 도출할 것임.\n",
    "                activation = 'sigmoid'))    # 출력은 0, 1으로 뽑는 활성화 함수 sigmoid 실행"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "source": [
    "model.compile(loss = 'binary_crossentropy', # loss 측정 함수로 채택\n",
    "              optimizer='adam',             # 최적화를 adam으로 지정\n",
    "              metrics=['accuracy', 'mse'])  # 정확도와 MSE를 출력하라는 의미\n",
    "model.fit(X, y,                             # feature, label 지정\n",
    "          epochs = 100,                     # 훈련은 100회 진행\n",
    "          batch_size= 10)                   # 한번에 10개 넣기"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch 1/100\n",
      "47/47 [==============================] - 1s 1ms/step - loss: 4.4016 - accuracy: 0.7957 - mse: 0.1872\n",
      "Epoch 2/100\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 0.7866 - accuracy: 0.7489 - mse: 0.2039\n",
      "Epoch 3/100\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 0.5359 - accuracy: 0.8234 - mse: 0.1479\n",
      "Epoch 4/100\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 0.5155 - accuracy: 0.7979 - mse: 0.1464\n",
      "Epoch 5/100\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 0.4484 - accuracy: 0.8340 - mse: 0.1337\n",
      "Epoch 6/100\n",
      "47/47 [==============================] - 0s 1ms/step - loss: 0.4689 - accuracy: 0.8298 - mse: 0.1360\n",
      "Epoch 7/100\n",
      "47/47 [==============================] - 0s 1ms/step - loss: 0.5596 - accuracy: 0.8000 - mse: 0.1485\n",
      "Epoch 8/100\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 0.4803 - accuracy: 0.8340 - mse: 0.1352\n",
      "Epoch 9/100\n",
      "47/47 [==============================] - 0s 1ms/step - loss: 0.4622 - accuracy: 0.8426 - mse: 0.1370\n",
      "Epoch 10/100\n",
      "47/47 [==============================] - 0s 1ms/step - loss: 0.4790 - accuracy: 0.8383 - mse: 0.1366\n",
      "Epoch 11/100\n",
      "47/47 [==============================] - 0s 1ms/step - loss: 0.4295 - accuracy: 0.8426 - mse: 0.1278\n",
      "Epoch 12/100\n",
      "47/47 [==============================] - 0s 1ms/step - loss: 0.4667 - accuracy: 0.8383 - mse: 0.1348\n",
      "Epoch 13/100\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 0.4471 - accuracy: 0.8426 - mse: 0.1325\n",
      "Epoch 14/100\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 0.4636 - accuracy: 0.8447 - mse: 0.1317\n",
      "Epoch 15/100\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 0.4364 - accuracy: 0.8489 - mse: 0.1296\n",
      "Epoch 16/100\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 0.4353 - accuracy: 0.8511 - mse: 0.1283\n",
      "Epoch 17/100\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 0.4532 - accuracy: 0.8319 - mse: 0.1343\n",
      "Epoch 18/100\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 0.4548 - accuracy: 0.8511 - mse: 0.1286\n",
      "Epoch 19/100\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 0.4228 - accuracy: 0.8468 - mse: 0.1269\n",
      "Epoch 20/100\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 0.4348 - accuracy: 0.8489 - mse: 0.1286\n",
      "Epoch 21/100\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 0.4688 - accuracy: 0.8319 - mse: 0.1347\n",
      "Epoch 22/100\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 0.4344 - accuracy: 0.8447 - mse: 0.1270\n",
      "Epoch 23/100\n",
      "47/47 [==============================] - 0s 1ms/step - loss: 0.4358 - accuracy: 0.8404 - mse: 0.1288\n",
      "Epoch 24/100\n",
      "47/47 [==============================] - 0s 1ms/step - loss: 0.4715 - accuracy: 0.8298 - mse: 0.1433\n",
      "Epoch 25/100\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 0.4253 - accuracy: 0.8489 - mse: 0.1271\n",
      "Epoch 26/100\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 0.4367 - accuracy: 0.8404 - mse: 0.1284\n",
      "Epoch 27/100\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 0.5032 - accuracy: 0.8362 - mse: 0.1394\n",
      "Epoch 28/100\n",
      "47/47 [==============================] - 0s 3ms/step - loss: 0.4339 - accuracy: 0.8489 - mse: 0.1271\n",
      "Epoch 29/100\n",
      "47/47 [==============================] - 0s 1ms/step - loss: 0.4512 - accuracy: 0.8298 - mse: 0.1355\n",
      "Epoch 30/100\n",
      "47/47 [==============================] - 0s 1ms/step - loss: 0.4570 - accuracy: 0.8447 - mse: 0.1343\n",
      "Epoch 31/100\n",
      "47/47 [==============================] - 0s 1ms/step - loss: 0.5392 - accuracy: 0.8340 - mse: 0.1374\n",
      "Epoch 32/100\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.4862 - accuracy: 0.8213 - mse: 0.1417\n",
      "Epoch 33/100\n",
      "47/47 [==============================] - 0s 3ms/step - loss: 0.4884 - accuracy: 0.8426 - mse: 0.1350\n",
      "Epoch 34/100\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 0.4590 - accuracy: 0.8447 - mse: 0.1316\n",
      "Epoch 35/100\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 0.4177 - accuracy: 0.8468 - mse: 0.1258\n",
      "Epoch 36/100\n",
      "47/47 [==============================] - 0s 1ms/step - loss: 0.4181 - accuracy: 0.8404 - mse: 0.1263\n",
      "Epoch 37/100\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 0.4073 - accuracy: 0.8553 - mse: 0.1222\n",
      "Epoch 38/100\n",
      "47/47 [==============================] - 0s 3ms/step - loss: 0.5684 - accuracy: 0.8021 - mse: 0.1494\n",
      "Epoch 39/100\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 0.4311 - accuracy: 0.8362 - mse: 0.1268\n",
      "Epoch 40/100\n",
      "47/47 [==============================] - 0s 3ms/step - loss: 0.4201 - accuracy: 0.8489 - mse: 0.1271\n",
      "Epoch 41/100\n",
      "47/47 [==============================] - 0s 1ms/step - loss: 0.4099 - accuracy: 0.8511 - mse: 0.1211\n",
      "Epoch 42/100\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 0.4150 - accuracy: 0.8532 - mse: 0.1234\n",
      "Epoch 43/100\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 0.4197 - accuracy: 0.8489 - mse: 0.1234\n",
      "Epoch 44/100\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 0.4204 - accuracy: 0.8404 - mse: 0.1243\n",
      "Epoch 45/100\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 0.4112 - accuracy: 0.8574 - mse: 0.1209\n",
      "Epoch 46/100\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 0.4643 - accuracy: 0.8255 - mse: 0.1320\n",
      "Epoch 47/100\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 0.4704 - accuracy: 0.8383 - mse: 0.1295\n",
      "Epoch 48/100\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 0.4297 - accuracy: 0.8426 - mse: 0.1272\n",
      "Epoch 49/100\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 0.4196 - accuracy: 0.8532 - mse: 0.1254\n",
      "Epoch 50/100\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 0.4071 - accuracy: 0.8511 - mse: 0.1223\n",
      "Epoch 51/100\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 0.4216 - accuracy: 0.8447 - mse: 0.1257\n",
      "Epoch 52/100\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 0.4269 - accuracy: 0.8340 - mse: 0.1274\n",
      "Epoch 53/100\n",
      "47/47 [==============================] - 0s 1ms/step - loss: 0.4439 - accuracy: 0.8468 - mse: 0.1263\n",
      "Epoch 54/100\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 0.5701 - accuracy: 0.8000 - mse: 0.1501\n",
      "Epoch 55/100\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 0.4083 - accuracy: 0.8553 - mse: 0.1208\n",
      "Epoch 56/100\n",
      "47/47 [==============================] - 0s 1ms/step - loss: 0.4292 - accuracy: 0.8532 - mse: 0.1261\n",
      "Epoch 57/100\n",
      "47/47 [==============================] - 0s 1ms/step - loss: 0.4275 - accuracy: 0.8404 - mse: 0.1270\n",
      "Epoch 58/100\n",
      "47/47 [==============================] - 0s 1ms/step - loss: 0.4148 - accuracy: 0.8532 - mse: 0.1210\n",
      "Epoch 59/100\n",
      "47/47 [==============================] - 0s 1ms/step - loss: 0.4220 - accuracy: 0.8426 - mse: 0.1253\n",
      "Epoch 60/100\n",
      "47/47 [==============================] - 0s 1ms/step - loss: 0.4507 - accuracy: 0.8426 - mse: 0.1318\n",
      "Epoch 61/100\n",
      "47/47 [==============================] - 0s 1ms/step - loss: 0.4026 - accuracy: 0.8426 - mse: 0.1236\n",
      "Epoch 62/100\n",
      "47/47 [==============================] - 0s 1ms/step - loss: 0.4114 - accuracy: 0.8489 - mse: 0.1232\n",
      "Epoch 63/100\n",
      "47/47 [==============================] - 0s 1ms/step - loss: 0.4329 - accuracy: 0.8468 - mse: 0.1277\n",
      "Epoch 64/100\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 0.4011 - accuracy: 0.8553 - mse: 0.1201\n",
      "Epoch 65/100\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 0.3989 - accuracy: 0.8489 - mse: 0.1175\n",
      "Epoch 66/100\n",
      "47/47 [==============================] - 0s 1ms/step - loss: 0.4194 - accuracy: 0.8426 - mse: 0.1247\n",
      "Epoch 67/100\n",
      "47/47 [==============================] - 0s 1ms/step - loss: 0.4371 - accuracy: 0.8404 - mse: 0.1294\n",
      "Epoch 68/100\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 0.4695 - accuracy: 0.8277 - mse: 0.1346\n",
      "Epoch 69/100\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 0.4093 - accuracy: 0.8426 - mse: 0.1210\n",
      "Epoch 70/100\n",
      "47/47 [==============================] - 0s 3ms/step - loss: 0.4267 - accuracy: 0.8298 - mse: 0.1235\n",
      "Epoch 71/100\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 0.4532 - accuracy: 0.8404 - mse: 0.1220\n",
      "Epoch 72/100\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 0.4606 - accuracy: 0.8404 - mse: 0.1325\n",
      "Epoch 73/100\n",
      "47/47 [==============================] - 0s 1ms/step - loss: 0.4206 - accuracy: 0.8447 - mse: 0.1217\n",
      "Epoch 74/100\n",
      "47/47 [==============================] - 0s 1ms/step - loss: 0.4085 - accuracy: 0.8404 - mse: 0.1200\n",
      "Epoch 75/100\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 0.4106 - accuracy: 0.8511 - mse: 0.1206\n",
      "Epoch 76/100\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 0.4589 - accuracy: 0.8404 - mse: 0.1332\n",
      "Epoch 77/100\n",
      "47/47 [==============================] - 0s 1ms/step - loss: 0.5797 - accuracy: 0.8149 - mse: 0.1531\n",
      "Epoch 78/100\n",
      "47/47 [==============================] - 0s 3ms/step - loss: 0.3989 - accuracy: 0.8553 - mse: 0.1170\n",
      "Epoch 79/100\n",
      "47/47 [==============================] - 0s 1ms/step - loss: 0.4315 - accuracy: 0.8468 - mse: 0.1228\n",
      "Epoch 80/100\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 0.4030 - accuracy: 0.8511 - mse: 0.1181\n",
      "Epoch 81/100\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 0.4065 - accuracy: 0.8489 - mse: 0.1208\n",
      "Epoch 82/100\n",
      "47/47 [==============================] - 0s 1ms/step - loss: 0.3972 - accuracy: 0.8553 - mse: 0.1196\n",
      "Epoch 83/100\n",
      "47/47 [==============================] - 0s 1ms/step - loss: 0.4051 - accuracy: 0.8383 - mse: 0.1230\n",
      "Epoch 84/100\n",
      "47/47 [==============================] - 0s 1ms/step - loss: 0.4400 - accuracy: 0.8532 - mse: 0.1250\n",
      "Epoch 85/100\n",
      "47/47 [==============================] - 0s 1ms/step - loss: 0.4621 - accuracy: 0.8362 - mse: 0.1314\n",
      "Epoch 86/100\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 0.4248 - accuracy: 0.8277 - mse: 0.1266\n",
      "Epoch 87/100\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 0.4366 - accuracy: 0.8404 - mse: 0.1255\n",
      "Epoch 88/100\n",
      "47/47 [==============================] - 0s 1ms/step - loss: 0.4079 - accuracy: 0.8426 - mse: 0.1219\n",
      "Epoch 89/100\n",
      "47/47 [==============================] - 0s 1ms/step - loss: 0.3989 - accuracy: 0.8638 - mse: 0.1153\n",
      "Epoch 90/100\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 0.4699 - accuracy: 0.8234 - mse: 0.1308\n",
      "Epoch 91/100\n",
      "47/47 [==============================] - 0s 1ms/step - loss: 0.4738 - accuracy: 0.8447 - mse: 0.1291\n",
      "Epoch 92/100\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 0.4098 - accuracy: 0.8553 - mse: 0.1195\n",
      "Epoch 93/100\n",
      "47/47 [==============================] - 0s 1ms/step - loss: 0.4250 - accuracy: 0.8426 - mse: 0.1264\n",
      "Epoch 94/100\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 0.4454 - accuracy: 0.8404 - mse: 0.1252\n",
      "Epoch 95/100\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 0.4316 - accuracy: 0.8426 - mse: 0.1259\n",
      "Epoch 96/100\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 0.4304 - accuracy: 0.8319 - mse: 0.1269\n",
      "Epoch 97/100\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 0.4261 - accuracy: 0.8553 - mse: 0.1240\n",
      "Epoch 98/100\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 0.3904 - accuracy: 0.8426 - mse: 0.1173\n",
      "Epoch 99/100\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 0.4587 - accuracy: 0.8447 - mse: 0.1260\n",
      "Epoch 100/100\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 0.3948 - accuracy: 0.8638 - mse: 0.1154\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fc1117ea490>"
      ]
     },
     "metadata": {},
     "execution_count": 45
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python",
   "version": "3.9.6",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.9.6 64-bit ('pythonProject4': conda)"
  },
  "interpreter": {
   "hash": "0e532115abeb172ccd0a16786b6fed74bf6c6a181c5a849b853367ec4b51c499"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}